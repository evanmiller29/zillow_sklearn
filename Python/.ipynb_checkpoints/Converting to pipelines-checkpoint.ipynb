{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion from top predictive model to pipelines\n",
    "\n",
    "I'll be using this script and seeing how easy it is to convert to the pipeline methodology.\n",
    "\n",
    "https://www.kaggle.com/aharless/xgboost-using-4th-quarter-for-validation/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Evan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.regression.quantile_regression import QuantReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('C:/Users/Evan/Documents/GitHub/Zillow/data')\n",
    "\n",
    "properties = pd.read_csv('../input/properties_2016.csv')\n",
    "properties17 = pd.read_csv('../input/properties_2017.csv')\n",
    "\n",
    "\n",
    "# Number of properties in the zip\n",
    "zip_count = properties['regionidzip'].value_counts().to_dict()\n",
    "# Number of properties in the city\n",
    "city_count = properties['regionidcity'].value_counts().to_dict()\n",
    "# Median year of construction by neighborhood\n",
    "medyear = properties.groupby('regionidneighborhood')['yearbuilt'].aggregate('median').to_dict()\n",
    "# Mean square feet by neighborhood\n",
    "meanarea = properties.groupby('regionidneighborhood')['calculatedfinishedsquarefeet'].aggregate('mean').to_dict()\n",
    "# Neighborhood latitude and longitude\n",
    "medlat = properties.groupby('regionidneighborhood')['latitude'].aggregate('median').to_dict()\n",
    "medlong = properties.groupby('regionidneighborhood')['longitude'].aggregate('median').to_dict()\n",
    "\n",
    "train = pd.read_csv(\"../input/train_2016_v2.csv\")\n",
    "for c in properties.columns:\n",
    "    properties[c]=properties[c].fillna(-1)\n",
    "    if properties[c].dtype == 'object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(properties[c].values))\n",
    "        properties[c] = lbl.transform(list(properties[c].values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
